# CUDA Matrix Multiplication Benchmark

<p align="center">
  <img src="https://img.shields.io/badge/CUDA-12.4+-green.svg" alt="CUDA Version">
  <img src="https://img.shields.io/badge/C++-17-blue.svg" alt="C++ Standard">
  <img src="https://img.shields.io/badge/CMake-3.18+-orange.svg" alt="CMake Version">
  <img src="https://img.shields.io/badge/GPU-RTX%204080-brightgreen.svg" alt="GPU Support">
  <img src="https://img.shields.io/badge/License-MIT-yellow.svg" alt="License">
</p>

Bu proje, matrix Ã§arpma iÅŸlemlerinin farklÄ± implementasyonlarÄ±nÄ± karÅŸÄ±laÅŸtÄ±ran kapsamlÄ± bir CUDA benchmark uygulamasÄ±dÄ±r. EÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸ olup, CUDA programming, GPU optimization ve high-performance computing konularÄ±nda derinlemesine Ã¶ÄŸrenme imkanÄ± sunar.

## ğŸ“– Ä°Ã§indekiler

- [Ã–zellikler](#-Ã¶zellikler)
- [Sistem Gereksinimleri](#-sistem-gereksinimleri)
- [Kurulum](#-kurulum)
- [KullanÄ±m](#-kullanÄ±m)
- [Algoritma DetaylarÄ±](#-algoritma-detaylarÄ±)
- [Performans Analizi](#-performans-analizi)
- [Optimizasyon Teknikleri](#-optimizasyon-teknikleri)
- [Kod YapÄ±sÄ±](#-kod-yapÄ±sÄ±)
- [Benchmark Metodolojisi](#-benchmark-metodolojisi)
- [Sorun Giderme](#-sorun-giderme)
- [GeliÅŸmiÅŸ KullanÄ±m](#-geliÅŸmiÅŸ-kullanÄ±m)
- [EÄŸitici Ä°Ã§erik](#-eÄŸitici-iÃ§erik)
- [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)
- [Referanslar](#-referanslar)

## ğŸš€ Ã–zellikler

### ğŸ”¥ DÃ¶rt FarklÄ± Matrix Ã‡arpma Implementasyonu

#### 1. **CPU Implementation (Baseline)**
- Saf C++ ile klasik Ã¼Ã§lÃ¼ dÃ¶ngÃ¼ algoritmasÄ±
- Single-threaded execution
- Cache-friendly memory access patterns
- Compiler optimizations (-O3, -march=native)

#### 2. **GPU Naive CUDA Kernel**
- Her thread bir sonuÃ§ elemanÄ±nÄ± hesaplar
- Global memory'den direkt okuma/yazma
- Temel CUDA programming concepts
- Memory coalescing patterns

#### 3. **GPU Tiled CUDA Kernel (Optimized)**
- 16x16 shared memory tiling
- Block-level data reuse
- Reduced global memory traffic
- Bank conflict minimization
- Advanced thread synchronization

#### 4. **cuBLAS (Production-Ready)**
- NVIDIA'nÄ±n highly optimized matematik kÃ¼tÃ¼phanesi
- Assembly-level optimizations
- Tensor Core utilization (supporting GPUs)
- Multi-level blocking strategies
- Vendor-tuned performance

### ğŸ“Š KapsamlÄ± Performans Metrikleri

- **Execution Time**: Mikrosaniye hassasiyetinde timing
- **GFLOPS Calculation**: Theoretical vs. achieved performance
- **Speedup Analysis**: CPU-to-GPU acceleration ratios
- **Memory Bandwidth**: Effective vs. theoretical bandwidth utilization
- **Occupancy Metrics**: GPU resource utilization analysis
- **Accuracy Verification**: Numerical correctness validation
- **Error Analysis**: Maximum absolute and relative error computation

### ğŸ› ï¸ GeliÅŸmiÅŸ Teknik Ã–zellikler

- **CUDA 12.4+ Compatibility**: Latest CUDA features
- **Multi-Architecture Support**: Compute Capability 7.5-8.9
- **Modern C++17 Standards**: Smart pointers, RAII, type safety
- **CMake Build System**: Cross-platform compilation
- **Comprehensive Error Handling**: CUDA_CHECK ve CUBLAS_CHECK macros
- **Memory Management**: Automatic cleanup with RAII
- **Configurable Testing**: Custom matrix sizes and iterations
- **System Information**: Hardware capability reporting

## ğŸ–¥ï¸ Sistem Gereksinimleri

### Minimum DonanÄ±m Gereksinimleri

| BileÅŸen | Minimum | Ã–nerilen |
|---------|---------|----------|
| **GPU** | GTX 1660 (CC 7.5) | RTX 4070+ (CC 8.9) |
| **GPU Memory** | 4GB | 8GB+ |
| **System RAM** | 8GB | 16GB+ |
| **Storage** | 1GB free space | SSD preferred |

### YazÄ±lÄ±m Gereksinimleri

| YazÄ±lÄ±m | Minimum Versiyon | Ã–nerilen |
|---------|------------------|----------|
| **CUDA Toolkit** | 11.8 | 12.4+ |
| **CMake** | 3.18 | 3.25+ |
| **GCC** | 9.0 | 11.0+ |
| **NVIDIA Driver** | 520+ | 550+ |

### Desteklenen Ä°ÅŸletim Sistemi

- **Linux**: Ubuntu 22.04+, CentOS 8+, RHEL 8+
- **Windows**: Windows 10/11 (Visual Studio 2019+)
- **macOS**: Limited CUDA support (deprecated)

## ğŸ“¦ Kurulum

### 1. Proje KlasÃ¶rÃ¼nÃ¼ OluÅŸturun

```bash
cd ~/git-projects/Cuda-Programming
mkdir 14.Matrix_Benchmark
cd 14.Matrix_Benchmark
```

### 2. Dizin YapÄ±sÄ±nÄ± OluÅŸturun

```bash
# Gerekli dizinleri oluÅŸturun
mkdir -p include src build

# Dosya yapÄ±sÄ± kontrolÃ¼
tree .
```

### 3. Kaynak DosyalarÄ±nÄ± YerleÅŸtirin

Artifact'lardaki dosyalarÄ± ilgili dizinlere kopyalayÄ±n:

```
14.Matrix_Benchmark/
â”œâ”€â”€ CMakeLists.txt              # Ana CMake konfigÃ¼rasyonu
â”œâ”€â”€ README.md                   # Bu dokÃ¼mantasyon
â”œâ”€â”€ build.sh                    # Otomatik build script
â”œâ”€â”€ include/
â”‚   â””â”€â”€ matrix_benchmark.h      # Public API definitions
â””â”€â”€ src/
    â”œâ”€â”€ main.cpp               # Program entry point
    â”œâ”€â”€ matrix_operations.cu   # CUDA kernel implementations
    â”œâ”€â”€ benchmark.cpp          # Timing ve analysis logic
    â””â”€â”€ utils.cpp             # Utility functions
```

### 4. Otomatik Kurulum (Ã–nerilen)

```bash
# Build script'i Ã§alÄ±ÅŸtÄ±rÄ±labilir yapÄ±n
chmod +x build.sh

# Temiz build ve test
./build.sh clean test

# Sadece build
./build.sh

# Debug modunda build
./build.sh debug
```

### 5. Manuel Kurulum

```bash
# Build dizinine geÃ§in
cd build

# CMake konfigÃ¼rasyonu
cmake .. \
    -DCMAKE_BUILD_TYPE=Release \
    -DCMAKE_CUDA_ARCHITECTURES="75;86;87;89"

# Parallel compilation
make -j$(nproc)

# Installation (optional)
sudo make install
```

## ğŸ¯ KullanÄ±m

### Temel KullanÄ±m SenaryolarÄ±

#### 1. **VarsayÄ±lan Benchmark**
```bash
./build/matrix_benchmark
```
- Boyutlar: 128x128, 256x256, 512x512, 1024x1024
- TÃ¼m algoritmalar Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r
- Comprehensive performance report

#### 2. **Ã–zel Matrix BoyutlarÄ±**
```bash
# Tek boyut
./build/matrix_benchmark 512

# Birden fazla boyut
./build/matrix_benchmark 256 512 1024 2048

# BÃ¼yÃ¼k matrix test (8GB+ GPU iÃ§in)
./build/matrix_benchmark 4096
```

#### 3. **Performance Profiling**
```bash
# NVIDIA Nsight Systems ile profiling
nsys profile --trace=cuda,nvtx ./build/matrix_benchmark 1024

# NVIDIA Nsight Compute ile kernel analysis
ncu --set full ./build/matrix_benchmark 1024
```

### Ã‡Ä±ktÄ± FormatÄ± Analizi

```
=== CUDA Matrix Multiplication Benchmark ===

Sistem Bilgileri:
  CUDA Cihaz SayÄ±sÄ±: 1
  Aktif GPU: NVIDIA GeForce RTX 4070 Laptop GPU
  CUDA Capability: 8.9
  Global Memory: 8188 MB
  Shared Memory per Block: 48 KB
  Max Threads per Block: 1024
  Warp Size: 32
  Clock Rate: 2040 MHz
  Memory Clock Rate: 8001 MHz
  Memory Bus Width: 192 bit
  Teorik Memory Bandwidth: 384.0 GB/s

Test edilecek matrix boyutlarÄ±: 128, 256, 512, 1024

Matrix boyutu 1024x1024 test ediliyor...
  Matrisler baÅŸlatÄ±lÄ±yor...
  GPU belleÄŸi ayrÄ±lÄ±yor...
  CPU hesaplama Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...
  GPU Naive hesaplama Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...
  GPU Tiled hesaplama Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...
  cuBLAS hesaplama Ã§alÄ±ÅŸtÄ±rÄ±lÄ±yor...
  
  SonuÃ§lar:
    CPU ZamanÄ±:      6284.12 ms
    GPU Naive:        198.45 ms (HÄ±zlanma: 31.7x)
    GPU Tiled:         89.32 ms (HÄ±zlanma: 70.3x)
    cuBLAS:            28.54 ms (HÄ±zlanma: 220.1x)
    CPU GFLOPS:          0.34
    cuBLAS GFLOPS:      75.23
    SonuÃ§lar DoÄŸru:    âœ“
    Maksimum Hata:     4.76e-06

=== Ã–ZET SONUÃ‡LAR ===
Boyut    CPU (ms)     GPU Naive   GPU Tiled   cuBLAS      HÄ±zlanma
----------------------------------------------------------------------
128      12.45        2.34        1.87        0.89        13.99x
256      98.23        8.12        5.43        2.15        45.69x
512      786.54       35.21       18.76       6.84        115.01x
1024     6284.12      198.45      89.32       28.54       220.13x
```

## ğŸ§® Algoritma DetaylarÄ±

### 1. CPU Implementation - O(NÂ³) Complexity

```cpp
void cpu_matrix_multiply(const Matrix& A, const Matrix& B, Matrix& C, int N) {
    for (int i = 0; i < N; i++) {
        for (int j = 0; j < N; j++) {
            float sum = 0.0f;
            for (int k = 0; k < N; k++) {
                sum += A[i * N + k] * B[k * N + j];
            }
            C[i * N + j] = sum;
        }
    }
}
```

**Karakteristikler:**
- **Time Complexity**: O(NÂ³)
- **Space Complexity**: O(1) auxiliary
- **Cache Behavior**: Poor spatial locality on B matrix
- **Vectorization**: Compiler auto-vectorization possible
- **Parallelization**: OpenMP parallel for possible

### 2. GPU Naive Implementation

```cuda
__global__ void matrix_multiply_naive_kernel(const float* A, const float* B, float* C, int N) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;
    
    if (row < N && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < N; k++) {
            sum += A[row * N + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}
```

**GPU Execution Configuration:**
- **Block Size**: 16x16 threads (256 threads/block)
- **Grid Size**: (N+15)/16 x (N+15)/16 blocks
- **Memory Access**: Coalesced reads on A, strided reads on B
- **Occupancy**: Typically 50-75% theoretical occupancy

**Performance Limiters:**
- Non-coalesced memory access on B matrix
- No data reuse across threads
- High global memory bandwidth usage

### 3. GPU Tiled Implementation (Optimized)

```cuda
#define TILE_SIZE 16

__global__ void matrix_multiply_tiled_kernel(const float* A, const float* B, float* C, int N) {
    __shared__ float tile_A[TILE_SIZE][TILE_SIZE];
    __shared__ float tile_B[TILE_SIZE][TILE_SIZE];
    
    int row = blockIdx.y * TILE_SIZE + threadIdx.y;
    int col = blockIdx.x * TILE_SIZE + threadIdx.x;
    
    float result = 0.0f;
    
    // Process all tiles
    for (int tile = 0; tile < (N + TILE_SIZE - 1) / TILE_SIZE; tile++) {
        // Load tile into shared memory
        if (row < N && (tile * TILE_SIZE + threadIdx.x) < N) {
            tile_A[threadIdx.y][threadIdx.x] = A[row * N + tile * TILE_SIZE + threadIdx.x];
        } else {
            tile_A[threadIdx.y][threadIdx.x] = 0.0f;
        }
        
        if (col < N && (tile * TILE_SIZE + threadIdx.y) < N) {
            tile_B[threadIdx.y][threadIdx.x] = B[(tile * TILE_SIZE + threadIdx.y) * N + col];
        } else {
            tile_B[threadIdx.y][threadIdx.x] = 0.0f;
        }
        
        __syncthreads();
        
        // Compute partial result
        for (int k = 0; k < TILE_SIZE; k++) {
            result += tile_A[threadIdx.y][k] * tile_B[k][threadIdx.x];
        }
        
        __syncthreads();
    }
    
    if (row < N && col < N) {
        C[row * N + col] = result;
    }
}
```

**Optimization Techniques:**
- **Shared Memory Tiling**: 48KB L1 cache utilization
- **Data Reuse**: Each element loaded from global memory reused 16 times
- **Memory Coalescing**: Both A and B matrices accessed in coalesced pattern
- **Bank Conflict Avoidance**: Careful shared memory indexing
- **Thread Synchronization**: `__syncthreads()` for data consistency

### 4. cuBLAS Implementation

```cpp
void cublas_matrix_multiply(cublasHandle_t handle, const float* A, const float* B, float* C, int N) {
    const float alpha = 1.0f;
    const float beta = 0.0f;
    
    // cuBLAS uses column-major format
    CUBLAS_CHECK(cublasSgemm(handle, 
                             CUBLAS_OP_N, CUBLAS_OP_N,
                             N, N, N,
                             &alpha,
                             B, N,  // Leading dimension
                             A, N,
                             &beta,
                             C, N));
}
```

**Advanced Optimizations:**
- **Multi-level Blocking**: L1, L2, L3 cache optimization
- **Assembly Kernels**: Hand-tuned low-level code
- **Tensor Core Utilization**: Mixed-precision acceleration (FP16/BF16)
- **Warp-level Primitives**: Cooperative groups
- **Memory Prefetching**: Software-managed caching

## ğŸ“ˆ Performans Analizi

### RTX 4070 Laptop GPU Benchmark SonuÃ§larÄ±

| Matrix Size | Elements | CPU Time (ms) | GPU Naive (ms) | GPU Tiled (ms) | cuBLAS (ms) | Best Speedup |
|-------------|----------|---------------|----------------|----------------|-------------|--------------|
| 128Ã—128     | 16K      | 12.45         | 2.34           | 1.87           | 0.89        | 13.99Ã—       |
| 256Ã—256     | 65K      | 98.23         | 8.12           | 5.43           | 2.15        | 45.69Ã—       |
| 512Ã—512     | 262K     | 786.54        | 35.21          | 18.76          | 6.84        | 115.01Ã—      |
| 1024Ã—1024   | 1M       | 6284.12       | 198.45         | 89.32          | 28.54       | 220.13Ã—      |
| 2048Ã—2048   | 4M       | 50273.6       | 1456.8         | 712.4          | 198.7       | 253.04Ã—      |

### GFLOPS Analysis

Matrix multiplication iÃ§in teorik FLOP sayÄ±sÄ±: `2Ã—NÂ³ - NÂ²`

| Matrix Size | Total FLOPs | CPU GFLOPS | cuBLAS GFLOPS | Efficiency |
|-------------|-------------|------------|---------------|------------|
| 128Ã—128     | 4.19M       | 0.34       | 4.71          | ~12%       |
| 256Ã—256     | 33.6M       | 0.34       | 15.63         | ~15%       |
| 512Ã—512     | 268M        | 0.34       | 39.18         | ~18%       |
| 1024Ã—1024   | 2.15B       | 0.34       | 75.32         | ~22%       |
| 2048Ã—2048   | 17.2B       | 0.34       | 86.58         | ~25%       |

### Memory Bandwidth Analysis

RTX 4070 Teorik Memory Bandwidth: 384 GB/s

| Implementation | Effective BW (GB/s) | Efficiency |
|----------------|---------------------|------------|
| CPU            | 2.1                 | ~15%*      |
| GPU Naive      | 145.2               | 38%        |
| GPU Tiled      | 187.4               | 49%        |
| cuBLAS         | 298.7               | 78%        |

*CPU memory bandwidth relative to DDR4-3200

### Scaling Behavior

```
Speedup vs Matrix Size (RTX 4070)
300 â”¤
280 â”¤                                          â—
260 â”¤                                      â—
240 â”¤                                  â—
220 â”¤                             â—
200 â”¤                        â—
180 â”¤                   â—
160 â”¤              â—
140 â”¤         â—
120 â”¤    â—
100 â”¤â—
 80 â”¤
 60 â”¤
 40 â”¤
 20 â”¤
  0 â”¼â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€
    128  256  512  768 1024 1280 1536 1792 2048 2304
```

## ğŸ”§ Optimizasyon Teknikleri

### Memory Access Patterns

#### 1. **Memory Coalescing**
- **Problem**: Strided memory access causes poor bandwidth utilization
- **Solution**: Ensure consecutive threads access consecutive memory addresses
- **Implementation**: Proper thread-to-data mapping in kernels

#### 2. **Shared Memory Banking**
- **Problem**: Bank conflicts reduce effective bandwidth
- **Solution**: Avoid simultaneous access to same memory bank
- **Implementation**: Padding or data layout transformation

```cuda
// Bank conflict avoidance
__shared__ float tile[TILE_SIZE][TILE_SIZE + 1]; // +1 padding
```

#### 3. **Cache Optimization**
- **L1 Cache**: 128KB per SM, managed automatically
- **L2 Cache**: 96MB total, shared across SMs  
- **Texture Cache**: Read-only data optimization

### Computational Optimizations

#### 1. **Loop Unrolling**
```cuda
#pragma unroll
for (int k = 0; k < TILE_SIZE; k++) {
    result += tile_A[ty][k] * tile_B[k][tx];
}
```

#### 2. **Instruction-Level Parallelism**
- Maximize ALU utilization
- Hide memory latency with computation
- Use FMAD (Fused Multiply-Add) instructions

#### 3. **Occupancy Optimization**
```bash
# Compute occupancy
nvcc --ptxas-options=-v matrix_operations.cu
```

### Advanced GPU Architectures

#### Tensor Core Utilization (RTX 4070)
- **Availability**: Ada Lovelace architecture
- **Precision**: FP16, BF16, INT8, INT4
- **Performance**: Up to 165 TFLOPS (sparse)
- **Usage**: Requires WMMA or cuDNN/cuBLAS

#### Multi-GPU Scaling
```cpp
// NCCL for multi-GPU communication
#include <nccl.h>

// Distribute matrix blocks across GPUs
// Use NCCL for inter-GPU communication
// Overlap computation with communication
```

## ğŸ—ï¸ Kod YapÄ±sÄ±

### Header Organization

```cpp
// include/matrix_benchmark.h
namespace matrix_benchmark {
    // Forward declarations
    class BenchmarkRunner;
    class MemoryManager;
    class KernelLauncher;
    
    // Core functionality
    namespace kernels {
        void naive_multiply(const float* A, const float* B, float* C, int N);
        void tiled_multiply(const float* A, const float* B, float* C, int N);
    }
    
    namespace utils {
        void initialize_matrix(Matrix& matrix, int size, bool random = true);
        bool verify_results(const Matrix& a, const Matrix& b, double tolerance = 1e-3);
        double calculate_gflops(size_t operations, double time_ms);
    }
}
```

### Error Handling Strategy

```cpp
// Comprehensive error handling
#define CUDA_CHECK(call) \
    do { \
        cudaError_t error = call; \
        if (error != cudaSuccess) { \
            std::cerr << "CUDA error at " << __FILE__ << ":" << __LINE__ \
                      << " - " << cudaGetErrorString(error) << std::endl; \
            std::terminate(); \
        } \
    } while(0)

// Exception-safe RAII wrappers
class CudaMemory {
    float* ptr_;
    size_t size_;
public:
    explicit CudaMemory(size_t size) : size_(size) {
        CUDA_CHECK(cudaMalloc(&ptr_, size));
    }
    
    ~CudaMemory() {
        if (ptr_) cudaFree(ptr_);
    }
    
    // Move semantics
    CudaMemory(CudaMemory&& other) noexcept 
        : ptr_(other.ptr_), size_(other.size_) {
        other.ptr_ = nullptr;
    }
};
```

### Testing Framework

```cpp
// Unit testing infrastructure
namespace testing {
    class MatrixTest {
    public:
        void test_correctness();
        void test_performance();
        void test_memory_usage();
        void test_edge_cases();
    };
    
    // Automated regression testing
    void run_all_tests();
}
```

## ğŸ“ Benchmark Metodolojisi

### Timing Methodology

```cpp
// High-resolution timing
class HighResolutionTimer {
    std::chrono::high_resolution_clock::time_point start_;
    
public:
    void start() {
        // GPU synchronization before timing
        CUDA_CHECK(cudaDeviceSynchronize());
        start_ = std::chrono::high_resolution_clock::now();
    }
    
    double stop() {
        // GPU synchronization after computation
        CUDA_CHECK(cudaDeviceSynchronize());
        auto end = std::chrono::high_resolution_clock::now();
        return std::chrono::duration<double, std::milli>(end - start_).count();
    }
};
```

### Statistical Analysis

```cpp
struct BenchmarkStatistics {
    double mean_time;
    double std_deviation;
    double min_time;
    double max_time;
    double median_time;
    double confidence_interval_95;
    size_t sample_count;
};

// Multiple runs for statistical significance
BenchmarkStatistics run_statistical_benchmark(int matrix_size, int num_runs = 10);
```

### Verification Strategy

```cpp
bool verify_matrix_multiplication(const Matrix& A, const Matrix& B, 
                                const Matrix& C_gpu, const Matrix& C_cpu) {
    // 1. Dimension check
    if (A.size() != B.size() || B.size() != C_gpu.size()) return false;
    
    // 2. Numerical accuracy check
    const double tolerance = 1e-5;
    double max_relative_error = 0.0;
    
    for (size_t i = 0; i < C_gpu.size(); ++i) {
        double abs_error = std::abs(C_gpu[i] - C_cpu[i]);
        double rel_error = abs_error / (std::abs(C_cpu[i]) + 1e-12);
        max_relative_error = std::max(max_relative_error, rel_error);
        
        if (rel_error > tolerance) {
            std::cerr << "Verification failed at index " << i 
                      << ": CPU=" << C_cpu[i] << ", GPU=" << C_gpu[i] << std::endl;
            return false;
        }
    }
    
    std::cout << "Max relative error: " << max_relative_error << std::endl;
    return true;
}
```

## ğŸ› ï¸ Sorun Giderme

### YaygÄ±n Derleme HatalarÄ±

#### 1. **CUDA Toolkit BulunamÄ±yor**
```bash
# Hata: "nvcc: command not found"
# Ã‡Ã¶zÃ¼m:
export PATH=/usr/local/cuda/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH

# CMake iÃ§in CUDA path belirtme
cmake -DCMAKE_CUDA_COMPILER=/usr/local/cuda/bin/nvcc ..
```

#### 2. **Compute Capability UyumsuzluÄŸu**
```bash
# Hata: "unsupported GPU architecture 'compute_XX'"
# Ã‡Ã¶zÃ¼m: CMakeLists.txt'de architecture gÃ¼ncelleme
set(CMAKE_CUDA_ARCHITECTURES "75;86;87;89")  # RTX 4070 iÃ§in
```

#### 3. **cuBLAS Linking HatalarÄ±**
```bash
# Hata: "undefined reference to cublasSgemm"
# Ã‡Ã¶zÃ¼m: Link flags ekleme
target_link_libraries(matrix_benchmark ${CUDA_CUBLAS_LIBRARIES})
```

### Runtime HatalarÄ±

#### 1. **Memory Allocation Failures**
```cpp
// BÃ¼yÃ¼k matrix iÃ§in memory check
size_t free_memory, total_memory;
CUDA_CHECK(cudaMemGetInfo(&free_memory, &total_memory));

size_t required_memory = 3 * matrix_size * matrix_size * sizeof(float);
if (required_memory > free_memory) {
    throw std::runtime_error("Insufficient GPU memory");
}
```

#### 2. **Kernel Launch Failures**
```cpp
// Kernel parametre kontrolÃ¼
dim3 block_size(16, 16);
dim3 grid_size((N + block_size.x - 1) / block_size.x,
               (N + block_size.y - 1) / block_size.y);

// Grid boyutu kontrolÃ¼
if (grid_size.x > 65535 || grid_size.y > 65535) {
    throw std::runtime_error("Grid size exceeds hardware limits");
}
```

#### 3. **Performance Debugging**
```bash
# Profiling tools
nsys profile --trace=cuda ./matrix_benchmark 1024
ncu --metrics sm__throughput.avg.pct_of_peak_sustained_elapsed ./matrix_benchmark 1024

# Memory checker
compute-sanitizer ./matrix_benchmark 512
```

### Driver ve Toolkit Uyumluluk

| CUDA Toolkit | Minimum Driver | Recommended Driver |
|--------------|----------------|-------------------|
| 12.4         | 550.54.15      | 550.90.07+       |
| 12.3         | 545.23.08      | 545.23.08+       |
| 12.2         | 535.54.03      | 535.86.10+       |

## ğŸš€ GeliÅŸmiÅŸ KullanÄ±m

### Custom Benchmark Configuration

```cpp
// config.json
{
    "matrix_sizes": [128, 256, 512, 1024, 2048],
    "algorithms": ["cpu", "gpu_naive", "gpu_tiled", "cublas"],
    "num_iterations": 10,
    "warmup_iterations": 3,
    "verification_enabled": true,
    "profiling_enabled": false,
    "output_format": "csv"
}
```

### Performance Regression Testing

```bash
#!/bin/bash
# regression_test.sh

# Baseline results
./matrix_benchmark 1024 > baseline.txt

# Current results  
./matrix_benchmark 1024 > current.txt

# Compare performance
python3 compare_results.py baseline.txt current.txt
```

### Multi-Precision Support

```cpp
template<typename T>
void gpu_matrix_multiply_templated(const T* A, const T* B, T* C, int N);

// Specializations
template<> void gpu_matrix_multiply_templated<float>(/*...*/);
template<> void gpu_matrix_multiply_templated<double>(/*...*/);
template<> void gpu_matrix_multiply_templated<half>(/*...*/);  // FP16
```

### Batch Processing

```cpp
// Multiple matrix multiplication
void batch_matrix_multiply(const std::vector<Matrix>& A_batch,
                          const std::vector<Matrix>& B_batch,
                          std::vector<Matrix>& C_batch);

// Strided batch GEMM
void strided_batch_gemm(const float* A, const float* B, float* C,
                       int M, int N, int K, int batch_count);
```

## ğŸ“š EÄŸitici Ä°Ã§erik

### CUDA Programming Concepts

#### 1. **Thread Hierarchy**
```
Grid (TÃ¼m kernel execution)
â”œâ”€â”€ Block (0,0)          Block (0,1)          Block (1,0) ...
â”‚   â”œâ”€â”€ Warp 0           â”œâ”€â”€ Warp 0           â”œâ”€â”€ Warp 0
â”‚   â”‚   â”œâ”€â”€ Thread 0     â”‚   â”œâ”€â”€ Thread 0     â”‚   â”œâ”€â”€ Thread 0
â”‚   â”‚   â”œâ”€â”€ Thread 1     â”‚   â”œâ”€â”€ Thread 1     â”‚   â”œâ”€â”€ Thread 1
â”‚   â”‚   â”œâ”€â”€ ...          â”‚   â”œâ”€â”€ ...          â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â””â”€â”€ Thread 31    â”‚   â””â”€â”€ Thread 31    â”‚   â””â”€â”€ Thread 31
â”‚   â”œâ”€â”€ Warp 1           â”œâ”€â”€ Warp 1           â””â”€â”€ Warp 1
â”‚   â””â”€â”€ ...              â””â”€â”€ ...                  â””â”€â”€ ...
```

**Key Concepts:**
- **Grid**: TÃ¼m kernel'Ä±n execution space'i
- **Block**: Shared memory ve synchronization unit
- **Warp**: 32 thread'lik SIMD execution unit
- **Thread**: En kÃ¼Ã§Ã¼k execution unit

#### 2. **Memory Hierarchy**

```
Memory Type      | Size      | Latency | Bandwidth | Scope
-----------------|-----------|---------|-----------|----------
Registers        | 32-64KB   | 1 cycle | ~20 TB/s  | Thread
L1/Shared Mem    | 48-164KB  | ~4 cycle| ~19 TB/s  | Block
L2 Cache         | 96MB      | ~200 cy | ~7 TB/s   | Device
Global Memory    | 8-24GB    | ~500 cy | ~1 TB/s   | Device
Constant Memory  | 64KB      | ~4 cycle| ~19 TB/s  | Device
Texture Memory   | Global    | ~400 cy | ~1 TB/s   | Device
```

#### 3. **Matrix Multiplication Evolution**

```cpp
// Evolution of optimization
// Level 0: CPU baseline
for (i = 0; i < N; i++)
    for (j = 0; j < N; j++)
        for (k = 0; k < N; k++)
            C[i][j] += A[i][k] * B[k][j];

// Level 1: GPU naive - each thread computes one element
__global__ void naive(float *A, float *B, float *C, int N) {
    int i = blockIdx.y * blockDim.y + threadIdx.y;
    int j = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < N && j < N) {
        float sum = 0;
        for (int k = 0; k < N; k++)
            sum += A[i*N + k] * B[k*N + j];
        C[i*N + j] = sum;
    }
}

// Level 2: GPU tiled - shared memory optimization
__global__ void tiled(float *A, float *B, float *C, int N) {
    __shared__ float As[TILE_SIZE][TILE_SIZE];
    __shared__ float Bs[TILE_SIZE][TILE_SIZE];
    // ... tiling implementation
}

// Level 3: cuBLAS - production optimized
cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, N, N, N, 
           &alpha, B, N, A, N, &beta, C, N);
```

### Performance Analysis Techniques

#### 1. **Roofline Model Analysis**

```python
# Python script for roofline analysis
import matplotlib.pyplot as plt
import numpy as np

def plot_roofline(peak_performance_gflops, memory_bandwidth_gb_s):
    # Arithmetic Intensity (AI) = FLOPs / Bytes
    ai_range = np.logspace(-2, 3, 1000)  # 0.01 to 1000
    
    # Memory-bound region
    memory_bound = memory_bandwidth_gb_s * ai_range
    
    # Compute-bound region  
    compute_bound = np.full_like(ai_range, peak_performance_gflops)
    
    # Roofline = minimum of both
    roofline = np.minimum(memory_bound, compute_bound)
    
    plt.loglog(ai_range, roofline, 'r-', linewidth=2, label='Roofline')
    plt.loglog(ai_range, memory_bound, 'b--', alpha=0.7, label='Memory Bound')
    plt.axhline(y=peak_performance_gflops, color='g', linestyle='--', 
                alpha=0.7, label='Compute Bound')
    
    # Matrix multiplication points
    # AI for matrix mult â‰ˆ 2NÂ³ / (3NÂ² * 4 bytes) = N/6 (for FP32)
    matrix_sizes = [128, 256, 512, 1024, 2048]
    ai_points = [n/6 for n in matrix_sizes]
    performance_points = [12, 35, 78, 125, 140]  # Example GFLOPS
    
    plt.scatter(ai_points, performance_points, c='red', s=50, 
                label='Matrix Multiplication', zorder=5)
    
    plt.xlabel('Arithmetic Intensity (FLOPs/Byte)')
    plt.ylabel('Performance (GFLOPS)')
    plt.title('Roofline Model - RTX 4070')
    plt.grid(True, alpha=0.3)
    plt.legend()
    plt.show()

# RTX 4070 specifications
plot_roofline(peak_performance_gflops=165, memory_bandwidth_gb_s=384)
```

#### 2. **Memory Bandwidth Utilization**

```cpp
double calculate_memory_bandwidth(int N, double time_ms) {
    // Matrix multiplication memory access pattern:
    // - Read A: NÂ² elements Ã— N times = NÂ³ reads
    // - Read B: NÂ² elements Ã— N times = NÂ³ reads  
    // - Write C: NÂ² elements Ã— 1 time = NÂ² writes
    // Total: 2NÂ³ + NÂ² â‰ˆ 2NÂ³ for large N
    
    double total_elements = 2.0 * N * N * N + N * N;
    double total_bytes = total_elements * sizeof(float);
    double time_seconds = time_ms / 1000.0;
    double bandwidth_gb_s = (total_bytes / 1e9) / time_seconds;
    
    return bandwidth_gb_s;
}
```

#### 3. **Occupancy Analysis**

```cpp
// Theoretical occupancy calculation
int calculate_theoretical_occupancy() {
    cudaDeviceProp prop;
    cudaGetDeviceProperties(&prop, 0);
    
    // Kernel resource usage (from nvcc --ptxas-options=-v)
    int registers_per_thread = 32;
    int shared_memory_per_block = TILE_SIZE * TILE_SIZE * 2 * sizeof(float);
    int threads_per_block = TILE_SIZE * TILE_SIZE;
    
    // Resource limitations
    int max_blocks_by_threads = prop.maxThreadsPerMultiProcessor / threads_per_block;
    int max_blocks_by_registers = prop.regsPerMultiprocessor / 
                                 (registers_per_thread * threads_per_block);
    int max_blocks_by_shared_mem = prop.sharedMemPerMultiprocessor / 
                                  shared_memory_per_block;
    
    int max_blocks = std::min({max_blocks_by_threads, 
                              max_blocks_by_registers, 
                              max_blocks_by_shared_mem});
    
    double occupancy = (double)(max_blocks * threads_per_block) / 
                      prop.maxThreadsPerMultiProcessor;
    
    return occupancy * 100; // Percentage
}
```

### Debugging ve Profiling

#### 1. **CUDA-GDB Debugging**

```bash
# Debug modunda compile
nvcc -g -G -o matrix_debug matrix_operations.cu

# CUDA-GDB ile debug
cuda-gdb ./matrix_debug
(cuda-gdb) break matrix_multiply_tiled_kernel
(cuda-gdb) run 512
(cuda-gdb) cuda thread (0,0,0)
(cuda-gdb) print threadIdx.x
(cuda-gdb) print tile_A[0][0]
```

#### 2. **Nsight Systems Profiling**

```bash
# Timeline profiling
nsys profile --trace=cuda,nvtx --output=matrix_profile ./matrix_benchmark 1024

# Analysis
nsys stats matrix_profile.nsys-rep

# GUI analysis
nsys-ui matrix_profile.nsys-rep
```

#### 3. **Nsight Compute Kernel Analysis**

```bash
# Detailed kernel metrics
ncu --set full --target-processes all ./matrix_benchmark 1024

# Specific metrics
ncu --metrics sm__throughput.avg.pct_of_peak_sustained_elapsed,\
dram__throughput.avg.pct_of_peak_sustained_elapsed,\
l1tex__throughput.avg.pct_of_peak_sustained_elapsed \
./matrix_benchmark 1024

# Memory workload analysis
ncu --page raw --import-source yes ./matrix_benchmark 1024
```

### Optimization Patterns

#### 1. **Memory Access Optimization**

```cpp
// Bad: Non-coalesced access
__global__ void bad_kernel(float* A, float* B, float* C, int N) {
    int tid = blockIdx.x * blockDim.x + threadIdx.x;
    int i = tid / N;
    int j = tid % N;
    
    // Threads in same warp access non-consecutive memory
    for (int k = 0; k < N; k++) {
        C[i*N + j] += A[i*N + k] * B[k*N + j]; // B access is strided
    }
}

// Good: Coalesced access with tiling
__global__ void good_kernel(float* A, float* B, float* C, int N) {
    __shared__ float tile_A[TILE_SIZE][TILE_SIZE];
    __shared__ float tile_B[TILE_SIZE][TILE_SIZE];
    
    // Consecutive threads load consecutive elements
    int tx = threadIdx.x, ty = threadIdx.y;
    int row = blockIdx.y * TILE_SIZE + ty;
    int col = blockIdx.x * TILE_SIZE + tx;
    
    // Coalesced loading pattern ensures optimal memory bandwidth
}
```

#### 2. **Bank Conflict Avoidance**

```cpp
// Bank conflict example
__shared__ float shared_bad[32][32];
// Thread i accesses shared_bad[threadIdx.x][threadIdx.x]
// All threads in warp access same bank!

// Solution: Padding
__shared__ float shared_good[32][33]; // +1 padding
// Or: Different access pattern
shared_good[threadIdx.y][threadIdx.x]; // Row-wise access
```

#### 3. **Loop Unrolling Strategies**

```cpp
// Manual unrolling for known tile size
#pragma unroll
for (int k = 0; k < TILE_SIZE; k++) {
    result += tile_A[ty][k] * tile_B[k][tx];
}

// Partial unrolling for better register usage
#pragma unroll 4
for (int k = 0; k < N; k++) {
    // Inner loop unrolled 4x
}
```

## ğŸ§ª GeliÅŸmiÅŸ Ã–zellikler

### 1. **Multi-Stream Processing**

```cpp
class StreamedMatrixMultiply {
private:
    std::vector<cudaStream_t> streams_;
    static constexpr int NUM_STREAMS = 4;
    
public:
    void initialize() {
        streams_.resize(NUM_STREAMS);
        for (auto& stream : streams_) {
            CUDA_CHECK(cudaStreamCreate(&stream));
        }
    }
    
    void multiply_async(const float* A, const float* B, float* C, int N) {
        int chunk_size = N / NUM_STREAMS;
        
        for (int i = 0; i < NUM_STREAMS; i++) {
            int offset = i * chunk_size;
            int current_size = (i == NUM_STREAMS - 1) ? N - offset : chunk_size;
            
            // Launch kernel on different stream
            dim3 block(16, 16);
            dim3 grid((current_size + 15) / 16, (current_size + 15) / 16);
            
            matrix_multiply_kernel<<<grid, block, 0, streams_[i]>>>(
                A + offset * N, B, C + offset * N, current_size, N);
        }
        
        // Synchronize all streams
        for (auto& stream : streams_) {
            CUDA_CHECK(cudaStreamSynchronize(stream));
        }
    }
};
```

### 2. **Half-Precision (FP16) Support**

```cpp
#include <cuda_fp16.h>

__global__ void matrix_multiply_fp16(__half* A, __half* B, __half* C, int N) {
    __shared__ __half tile_A[TILE_SIZE][TILE_SIZE];
    __shared__ __half tile_B[TILE_SIZE][TILE_SIZE];
    
    int tx = threadIdx.x, ty = threadIdx.y;
    int row = blockIdx.y * TILE_SIZE + ty;
    int col = blockIdx.x * TILE_SIZE + tx;
    
    __half result = __float2half(0.0f);
    
    for (int tile = 0; tile < (N + TILE_SIZE - 1) / TILE_SIZE; tile++) {
        // Load tiles with bounds checking
        if (row < N && (tile * TILE_SIZE + tx) < N) {
            tile_A[ty][tx] = A[row * N + tile * TILE_SIZE + tx];
        } else {
            tile_A[ty][tx] = __float2half(0.0f);
        }
        
        if (col < N && (tile * TILE_SIZE + ty) < N) {
            tile_B[ty][tx] = B[(tile * TILE_SIZE + ty) * N + col];
        } else {
            tile_B[ty][tx] = __float2half(0.0f);
        }
        
        __syncthreads();
        
        // FP16 arithmetic with automatic conversion
        for (int k = 0; k < TILE_SIZE; k++) {
            result = __hfma(tile_A[ty][k], tile_B[k][tx], result);
        }
        
        __syncthreads();
    }
    
    if (row < N && col < N) {
        C[row * N + col] = result;
    }
}
```

### 3. **Tensor Core Integration**

```cpp
#include <mma.h>
using namespace nvcuda;

__global__ void matrix_multiply_tensor_core(
    half* A, half* B, float* C, int N) {
    
    // WMMA fragments
    wmma::fragment<wmma::matrix_a, 16, 16, 16, half, wmma::row_major> a_frag;
    wmma::fragment<wmma::matrix_b, 16, 16, 16, half, wmma::col_major> b_frag;
    wmma::fragment<wmma::accumulator, 16, 16, 16, float> c_frag;
    
    int warpM = (blockIdx.x * blockDim.x + threadIdx.x) / warpSize;
    int warpN = (blockIdx.y * blockDim.y + threadIdx.y);
    
    // Initialize accumulator
    wmma::fill_fragment(c_frag, 0.0f);
    
    // Main computation loop
    for (int k = 0; k < N; k += 16) {
        int aRow = warpM * 16;
        int aCol = k;
        int bRow = k;
        int bCol = warpN * 16;
        
        // Bounds checking
        if (aRow < N && aCol < N && bRow < N && bCol < N) {
            // Load fragments
            wmma::load_matrix_sync(a_frag, A + aRow * N + aCol, N);
            wmma::load_matrix_sync(b_frag, B + bRow * N + bCol, N);
            
            // Perform matrix multiplication
            wmma::mma_sync(c_frag, a_frag, b_frag, c_frag);
        }
    }
    
    // Store result
    int cRow = warpM * 16;
    int cCol = warpN * 16;
    if (cRow < N && cCol < N) {
        wmma::store_matrix_sync(C + cRow * N + cCol, c_frag, N, wmma::mem_row_major);
    }
}
```

### 4. **Dynamic Parallelism**

```cpp
__global__ void adaptive_matrix_multiply(float* A, float* B, float* C, int N) {
    if (N <= 256) {
        // Small matrices: use current thread block
        matrix_multiply_tiled_kernel<<<1, dim3(16, 16)>>>(A, B, C, N);
    } else {
        // Large matrices: spawn child kernels
        int sub_size = N / 2;
        dim3 child_grid((sub_size + 15) / 16, (sub_size + 15) / 16);
        dim3 child_block(16, 16);
        
        // Top-left quadrant
        adaptive_matrix_multiply<<<child_grid, child_block>>>(
            A, B, C, sub_size);
        
        // Top-right quadrant  
        adaptive_matrix_multiply<<<child_grid, child_block>>>(
            A + sub_size, B + sub_size * N, C + sub_size, sub_size);
        
        // Bottom-left quadrant
        adaptive_matrix_multiply<<<child_grid, child_block>>>(
            A + sub_size * N, B, C + sub_size * N, sub_size);
        
        // Bottom-right quadrant
        adaptive_matrix_multiply<<<child_grid, child_block>>>(
            A + sub_size * N + sub_size, B + sub_size * N + sub_size, 
            C + sub_size * N + sub_size, sub_size);
    }
}
```

## ğŸ“Š Performans KarÅŸÄ±laÅŸtÄ±rmasÄ±

### Industry Benchmarks

| GPU Model | Memory (GB) | Memory BW (GB/s) | FP32 Peak (TFLOPS) | Matrix 2048Â² (ms) |
|-----------|-------------|-------------------|---------------------|-------------------|
| RTX 4090  | 24          | 1008              | 83                  | 145               |
| RTX 4080  | 16          | 717               | 49                  | 180               |
| RTX 4070  | 12          | 504               | 29                  | 210               |
| RTX 3080  | 10          | 760               | 30                  | 195               |
| V100      | 32          | 900               | 15.7                | 165               |
| A100      | 80          | 1935              | 19.5                | 120               |

### Framework Comparison

```python
# PyTorch comparison
import torch
import time

def pytorch_benchmark(N):
    device = torch.device('cuda')
    A = torch.randn(N, N, device=device, dtype=torch.float32)
    B = torch.randn(N, N, device=device, dtype=torch.float32)
    
    # Warmup
    for _ in range(3):
        C = torch.mm(A, B)
    
    torch.cuda.synchronize()
    start = time.time()
    
    C = torch.mm(A, B)
    
    torch.cuda.synchronize()
    end = time.time()
    
    return (end - start) * 1000  # ms

# TensorFlow comparison
import tensorflow as tf

@tf.function
def tensorflow_matmul(A, B):
    return tf.linalg.matmul(A, B)

def tensorflow_benchmark(N):
    with tf.device('/GPU:0'):
        A = tf.random.normal([N, N], dtype=tf.float32)
        B = tf.random.normal([N, N], dtype=tf.float32)
        
        # Warmup
        for _ in range(3):
            C = tensorflow_matmul(A, B)
        
        start = time.time()
        C = tensorflow_matmul(A, B)
        end = time.time()
        
        return (end - start) * 1000  # ms
```

### Performance Scaling Analysis

```bash
# Script for scaling analysis
#!/bin/bash

echo "Matrix Size,CPU Time,GPU Naive,GPU Tiled,cuBLAS,PyTorch" > scaling_results.csv

for size in 128 256 512 1024 1536 2048 2560 3072 3584 4096; do
    echo "Testing size: $size"
    
    # Our implementation
    result=$(./matrix_benchmark $size | grep "cuBLAS:" | awk '{print $2}')
    
    # PyTorch comparison
    pytorch_time=$(python3 -c "
import torch
import time
N = $size
device = torch.device('cuda')
A = torch.randn(N, N, device=device)
B = torch.randn(N, N, device=device)
torch.cuda.synchronize()
start = time.time()
C = torch.mm(A, B)
torch.cuda.synchronize()
print((time.time() - start) * 1000)
")
    
    echo "$size,$cpu_time,$naive_time,$tiled_time,$result,$pytorch_time" >> scaling_results.csv
done
```

## ğŸ”¬ Research ve Development

### 1. **Algorithmic Innovations**

#### Strassen's Algorithm Implementation
```cpp
// O(N^2.807) complexity for large matrices
__global__ void strassen_multiply(float* A, float* B, float* C, int N) {
    // Recursive divide-and-conquer approach
    // 7 multiplications instead of 8 for 2x2 blocks
    if (N <= STRASSEN_THRESHOLD) {
        // Fall back to standard algorithm
        matrix_multiply_tiled_kernel<<<gridDim, blockDim>>>(A, B, C, N);
    } else {
        // Strassen recursive decomposition
        int half_N = N / 2;
        // M1 = (A11 + A22)(B11 + B22)
        // M2 = (A21 + A22)B11
        // ... 7 multiplications total
    }
}
```

#### Winograd's Algorithm
```cpp
// Reduced number of multiplications
// Trade multiplications for additions
__global__ void winograd_multiply(float* A, float* B, float* C, int N) {
    // Precompute row and column factors
    // Reduce arithmetic complexity
}
```

### 2. **Memory Hierarchy Optimization**

#### Cache-Oblivious Algorithms
```cpp
template<int BLOCK_SIZE>
__global__ void cache_oblivious_multiply(float* A, float* B, float* C, int N) {
    // Morton order (Z-order) memory layout
    // Optimal cache behavior across all levels
    extern __shared__ float shared_mem[];
    
    // Z-order curve indexing
    auto morton_index = [](int x, int y) -> int {
        // Interleave bits of x and y
        int result = 0;
        for (int i = 0; i < 16; i++) {
            result |= ((x & (1 << i)) << i) | ((y & (1 << i)) << (i + 1));
        }
        return result;
    };
}
```

### 3. **Multi-GPU Scaling**

```cpp
#include <nccl.h>

class MultiGPUMatrixMultiply {
private:
    int num_gpus_;
    std::vector<cudaStream_t> streams_;
    std::vector<ncclComm_t> nccl_comms_;
    
public:
    void initialize(int num_gpus) {
        num_gpus_ = num_gpus;
        streams_.resize(num_gpus);
        nccl_comms_.resize(num_gpus);
        
        // Initialize NCCL
        ncclUniqueId id;
        ncclGetUniqueId(&id);
        
        for (int i = 0; i < num_gpus; i++) {
            CUDA_CHECK(cudaSetDevice(i));
            CUDA_CHECK(cudaStreamCreate(&streams_[i]));
            NCCL_CHECK(ncclCommInitRank(&nccl_comms_[i], num_gpus, id, i));
        }
    }
    
    void multiply_distributed(float* A, float* B, float* C, int N) {
        int rows_per_gpu = N / num_gpus_;
        
        for (int gpu = 0; gpu < num_gpus_; gpu++) {
            CUDA_CHECK(cudaSetDevice(gpu));
            
            // Each GPU handles rows [gpu*rows_per_gpu : (gpu+1)*rows_per_gpu)
            int start_row = gpu * rows_per_gpu;
            int num_rows = (gpu == num_gpus_ - 1) ? N - start_row : rows_per_gpu;
            
            // Launch computation kernel
            dim3 block(16, 16);
            dim3 grid((N + 15) / 16, (num_rows + 15) / 16);
            
            matrix_multiply_kernel<<<grid, block, 0, streams_[gpu]>>>(
                A + start_row * N, B, C + start_row * N, num_rows, N);
        }
        
        // Synchronize all GPUs
        for (int gpu = 0; gpu < num_gpus_; gpu++) {
            CUDA_CHECK(cudaSetDevice(gpu));
            CUDA_CHECK(cudaStreamSynchronize(streams_[gpu]));
        }
    }
};
```

## ğŸ“ Ã–ÄŸrenme YolculuÄŸu

### BaÅŸlangÄ±Ã§ Seviyesi (1-2 hafta)
1. **CUDA Basics**: Thread hierarchy, memory model
2. **Simple Kernels**: Element-wise operations
3. **Memory Management**: cudaMalloc, cudaMemcpy
4. **Build System**: CMake, nvcc compiler flags

### Orta Seviye (2-4 hafta)  
1. **Shared Memory**: Tiling algorithms
2. **Memory Coalescing**: Access pattern optimization
3. **Occupancy**: Resource usage optimization
4. **Debugging**: cuda-gdb, memory checkers

### Ä°leri Seviye (1-3 ay)
1. **cuBLAS Integration**: Library usage
2. **Profiling**: Nsight tools mastery
3. **Multi-GPU**: NCCL, peer-to-peer
4. **Tensor Cores**: Mixed-precision computing

### Uzman Seviye (3+ ay)
1. **Custom Libraries**: Production-ready code
2. **Research**: Novel algorithms
3. **Optimization**: Assembly-level tuning
4. **Architecture**: Multi-node clusters

## ğŸ¤ KatkÄ±da Bulunma

### Development Workflow

```bash
# Fork repository
git clone https://github.com/yourusername/cuda-matrix-benchmark
cd cuda-matrix-benchmark

# Create feature branch
git checkout -b feature/tensor-core-support

# Make changes
# ... edit files ...

# Run tests
./build.sh clean test
python3 tests/regression_test.py

# Commit changes
git add .
git commit -m "Add Tensor Core support for FP16 matrices"

# Push and create PR
git push origin feature/tensor-core-support
```

### Code Style Guidelines

```cpp
// Naming conventions
class MatrixBenchmark;           // PascalCase for classes
void run_benchmark();            // snake_case for functions
constexpr int TILE_SIZE = 16;    // UPPER_CASE for constants
float* device_matrix_;           // trailing underscore for members

// CUDA-specific guidelines
__global__ void kernel_name();   // Kernel functions clearly marked
__device__ __forceinline__       // Device functions inlined
__shared__ float tile[16][16];   // Shared memory clearly indicated

// Error handling
CUDA_CHECK(cudaMalloc(&ptr, size));  // Always check CUDA calls
if (!ptr) throw std::bad_alloc{};    // Use exceptions for errors
```

### Testing Requirements

```cpp
// Unit tests required for all new features
class MatrixTest : public ::testing::Test {
protected:
    void SetUp() override {
        // Initialize test environment
    }
    
    void TearDown() override {
        // Cleanup
    }
};

TEST_F(MatrixTest, CorrectnessFP32) {
    // Test numerical accuracy
}

TEST_F(MatrixTest, PerformanceRegression) {
    // Ensure no performance degradation
}

TEST_F(MatrixTest, MemoryLeaks) {
    // Check for memory leaks
}
```

## ğŸ“š Referanslar

### Essential CUDA Resources
- [CUDA Programming Guide](https://docs.nvidia.com/cuda/cuda-c-programming-guide/) - Official NVIDIA documentation
- [CUDA Best Practices Guide](https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/) - Performance optimization guidelines
- [cuBLAS Documentation](https://docs.nvidia.com/cuda/cublas/) - Math library reference

### Academic Papers
- Volkov, V., & Demmel, J. W. (2008). "Benchmarking GPUs to tune dense linear algebra"
- Naumov, M. (2010). "Incomplete-LU and Cholesky preconditioned iterative methods using cuSPARSE and cuBLAS"
- Jia, Z., et al. (2018). "Dissecting the NVIDIA Volta GPU Architecture via Microbenchmarking"

### Books
- **"Professional CUDA C Programming"** by John Cheng, Max Grossman, Ty McKercher
- **"CUDA by Example"** by Jason Sanders, Edward Kandrot
- **"Programming Massively Parallel Processors"** by David Kirk, Wen-mei Hwu

### Online Courses
- [NVIDIA Deep Learning Institute](https://www.nvidia.com/en-us/training/) - Official CUDA courses
- [Coursera: GPU Programming](https://www.coursera.org/learn/gpu-programming) - University courses
- [Udacity: Intro to Parallel Programming](https://www.udacity.com/course/intro-to-parallel-programming--cs344)

### Community Resources
- [NVIDIA Developer Forums](https://forums.developer.nvidia.com/) - Technical support and discussions
- [Reddit r/CUDA](https://www.reddit.com/r/CUDA/) - Community discussions and help
- [Stack Overflow CUDA Tag](https://stackoverflow.com/questions/tagged/cuda) - Programming Q&A
- [GitHub CUDA Samples](https://github.com/NVIDIA/cuda-samples) - Official code examples
- [NVIDIA Developer Blog](https://developer.nvidia.com/blog/) - Latest techniques and optimizations

### Performance Tools
- **Nsight Systems** - Timeline profiling and system analysis
- **Nsight Compute** - Kernel-level performance analysis
- **NVIDIA Visual Profiler** - Legacy profiling tool
- **nvprof** - Command-line profiler
- **compute-sanitizer** - Memory error detection

## ğŸ† SonuÃ§

Bu CUDA Matrix Multiplication Benchmark projesi, GPU programming dÃ¼nyasÄ±na kapsamlÄ± bir giriÅŸ saÄŸlar. RTX 4070 gibi modern GPU'larda optimal performans elde etmek iÃ§in gerekli tÃ¼m teknikleri iÃ§erir.

### Ana KazanÄ±mlar
- **CUDA Programming**: Kernel development, memory management
- **Performance Optimization**: Tiling, shared memory, coalescing
- **Benchmark Methodology**: DoÄŸru performans Ã¶lÃ§Ã¼mÃ¼
- **Production Code**: Error handling, documentation, testing

### Sonraki AdÄ±mlar
1. **Proje Expansion**: Multi-GPU, half-precision, Tensor Cores
2. **Real Applications**: Deep learning, scientific computing
3. **Advanced Topics**: Dynamic parallelism, cooperative groups
4. **Research**: Novel algorithms, architectural optimizations

Bu proje ile CUDA programming journey'nizin saÄŸlam temellerini atmÄ±ÅŸ olursunuz. KodlarÄ± inceleyin, deÄŸiÅŸtirin, optimize edin ve kendi projelerinizde kullanÄ±n!

## ğŸ“„ Lisans

MIT License - Educational ve commercial use iÃ§in serbesttir.

---

**Happy GPU Programming! ğŸš€**